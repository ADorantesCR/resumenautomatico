{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kBTFdjbctkXXHuyQ34HTXfQkvKBmEDCA",
      "authorship_tag": "ABX9TyN2Vp5JK8Hd0hLBO6qB+lNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ADorantesCR/resumenautomatico/blob/main/sintesisfinalviernes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas python-docx\n",
        "!pip install Pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W7OEKvnkBCy",
        "outputId": "142ab1e2-2656-4bff-dde7-eeed65927426"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (0.8.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########semarnat ANÁLISIS MÁS ÍNDICE#\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "\n",
        "# Ruta de la carpeta que contiene los archivos Excel\n",
        "ruta = '/content/drive/MyDrive/profepa-sintesis/Excel/SEMARNAT'\n",
        "\n",
        "# Obtener la lista de archivos Excel en la carpeta\n",
        "archivos_excel = [archivo for archivo in os.listdir(ruta) if archivo.endswith('.xlsx')]\n",
        "\n",
        "# DataFrame final\n",
        "df_finalS = pd.DataFrame()\n",
        "\n",
        "# Recorrer los archivos Excel y cargarlos en el DataFrame final\n",
        "for i, archivo in enumerate(archivos_excel):\n",
        "    archivo_path = os.path.join(ruta, archivo)\n",
        "    df = pd.read_excel(archivo_path)\n",
        "\n",
        "    # Eliminar las filas correspondientes según el archivo\n",
        "    if i == 0:\n",
        "        df = df.iloc[1:]  # Eliminar la primera fila\n",
        "    else:\n",
        "        df = df.iloc[2:]  # Eliminar las tres primeras filas\n",
        "\n",
        "    # Agregar el DataFrame al DataFrame final\n",
        "    df_finalS = pd.concat([df_finalS, df], ignore_index=True)\n",
        "\n",
        "# Utilizar la primera fila como cabeceras\n",
        "df_finalS.columns = df_finalS.iloc[0]\n",
        "df_finalS = df_finalS.iloc[1:]\n",
        "\n",
        "# Convertimos las columnas 'Fecha' y 'Hora' a datetime\n",
        "df_finalS['Fecha'] = pd.to_datetime(df_finalS['Fecha'])\n",
        "df_finalS['Hora'] = pd.to_timedelta(df_finalS['Hora'])\n",
        "\n",
        "# Creamos una nueva columna con la fecha y hora juntas\n",
        "df_finalS['FechaHora'] = df_finalS['Fecha'] + df_finalS['Hora']\n",
        "\n",
        "# Definimos la fecha y hora de inicio y fin\n",
        "fecha_inicio = pd.to_datetime('2023-06-29 17:00:00')\n",
        "fecha_fin = pd.to_datetime('2023-06-30 06:00:00')\n",
        "\n",
        "# Filtramos el dataframe para que solo queden las filas dentro del rango de fecha y hora\n",
        "df_finalS = df_finalS[(df_finalS['FechaHora'] >= fecha_inicio) & (df_finalS['FechaHora'] <= fecha_fin)]\n",
        "\n",
        "#copiamos la columan titulo para trabajar sobre ella\n",
        "df_finalS['Título_analisis'] = df_finalS['Título']\n",
        "\n",
        "# Descargar los stopwords si no están descargados\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Obtener los stopwords en español\n",
        "stopwords_esp = set(stopwords.words('spanish'))\n",
        "\n",
        "# Función para eliminar palabras vacías y manejar valores nulos\n",
        "def eliminar_palabras_vacias(texto):\n",
        "    if isinstance(texto, str):  # Verificar si el valor no es nulo\n",
        "        texto = re.sub(r'[^\\w\\s]', '', texto)  # Eliminar caracteres no deseados utilizando re.sub()\n",
        "        texto = texto.strip()  # Eliminar espacios en blanco adicionales al inicio y al final\n",
        "        palabras = texto.split()\n",
        "        palabras_filtradas = [palabra for palabra in palabras if palabra not in stopwords_esp]\n",
        "        return ' '.join(palabras_filtradas).lower()\n",
        "    else:\n",
        "        return texto\n",
        "\n",
        "# Aplicar la función a la columna 'Título_analisis'\n",
        "df_finalS['Título_analisis'] = df_finalS['Título_analisis'].apply(eliminar_palabras_vacias)\n",
        "\n",
        "# Verificar y convertir a cadena los valores no nulos en la columna \"Título_analisis\"\n",
        "df_finalS['Título_analisis'] = df_finalS['Título_analisis'].apply(lambda x: str(x) if pd.notnull(x) else '')\n",
        "\n",
        "grupos = {}\n",
        "for i in range(len(df_finalS)):\n",
        "    titulo_i = df_finalS.iloc[i, df_finalS.columns.get_loc(\"Título_analisis\")]\n",
        "    if i not in grupos:\n",
        "        grupo_actual = len(grupos) + 1\n",
        "        grupos[i] = grupo_actual\n",
        "    else:\n",
        "        grupo_actual = grupos[i]\n",
        "    for j in range(i+1, len(df_finalS)):\n",
        "        titulo_j = df_finalS.iloc[j, df_finalS.columns.get_loc(\"Título_analisis\")]\n",
        "        titulo_j = str(titulo_j) if pd.notnull(titulo_j) else ''\n",
        "        palabras_iguales = set(titulo_i.lower().split()) & set(titulo_j.lower().split())\n",
        "        if len(palabras_iguales) >= 3:\n",
        "            if j not in grupos:\n",
        "                grupos[j] = grupo_actual\n",
        "            else:\n",
        "                grupo_j = grupos[j]\n",
        "                if grupo_j != grupo_actual:\n",
        "                    for k, v in grupos.items():\n",
        "                        if v == grupo_j:\n",
        "                            grupos[k] = grupo_actual\n",
        "\n",
        "# Agregar una columna al DataFrame para mostrar los grupos\n",
        "df_finalS['Grupo'] = [grupos[i] for i in range(len(df_finalS))]\n",
        "\n",
        "grupo_counts = df_finalS['Grupo'].value_counts()\n",
        "df_finalS['Notas'] = df_finalS['Grupo'].apply(lambda x: grupo_counts[x])\n",
        "\n",
        "# Eliminar filas con NaN en la columna \"Título\"\n",
        "df_finalS = df_finalS.dropna(subset=['Título'])\n",
        "\n",
        "# Crear una nueva columna \"resautom\" en el dataframe df_final.\n",
        "df_finalS[\"resautom\"] = \"\"\n",
        "\n",
        "# Recorrer cada celda de la columna \"Transcripción\".\n",
        "for index, row in df_finalS.iterrows():\n",
        "    document = row[\"Transcripción\"]\n",
        "\n",
        "    # Utilizar expresiones regulares para buscar las oraciones relevantes.\n",
        "    pattern = re.compile(r\"(.*?[.!?])\", re.IGNORECASE)\n",
        "    relevant_sentences = re.findall(pattern, document)\n",
        "    relevant_sentences = [sentence.strip() for sentence in relevant_sentences if \"Semarnat\" in sentence.upper() or \"Secretaría de Medio Ambiente y Recursos Naturales\" in sentence or \"SEMARNAT\" in sentence]\n",
        "\n",
        "    # Unir las oraciones relevantes en una sola cadena de texto.\n",
        "    summary_text = \". \".join(relevant_sentences)\n",
        "\n",
        "    # Agregar el resultado a la columna \"resautom\" en el dataframe.\n",
        "    df_finalS.at[index, \"resautom\"] = summary_text\n",
        "\n",
        "\n",
        "################semarnat WORD INDICE##################\n",
        "\n",
        "# Crear un documento de Word\n",
        "document = Document()\n",
        "\n",
        "# Establecer el tipo de letra y tamaño de fuente\n",
        "font_name = \"Montserrat\"\n",
        "font_size = Pt(12)\n",
        "document.styles['Normal'].font.name = font_name\n",
        "document.styles['Normal'].font.size = font_size\n",
        "\n",
        "# Establecer los márgenes del documento como \"Estrecho\"\n",
        "sections = document.sections\n",
        "for section in sections:\n",
        "    section.top_margin = section.bottom_margin = section.left_margin = section.right_margin = Pt(31.8)  # 0.44 pulgadas\n",
        "\n",
        "# Establecer el interlineado\n",
        "line_spacing = 1.5\n",
        "\n",
        "# Agregar un encabezado al documento\n",
        "#document.add_heading('Índice', level=1)\n",
        "document.add_heading('SEMARNAT', level=1)\n",
        "\n",
        "# Agrupar por \"Grupo\" y seleccionar la primera fila de cada grupo\n",
        "df_grupos = df_finalS.groupby('Grupo').first()\n",
        "\n",
        "# Ordenar el DataFrame por la columna \"Notas\" en orden descendente\n",
        "df_grupos_sorted = df_grupos.sort_values(by='Notas', ascending=False)\n",
        "\n",
        "# Crear una lista de todos los títulos\n",
        "titulos_list = df_grupos_sorted['Título'].tolist()\n",
        "\n",
        "# Agregar el listado de títulos como un índice al documento\n",
        "#document.add_heading('Índice', level=1)\n",
        "for i, titulo in enumerate(titulos_list, start=1):\n",
        "    document.add_paragraph(f'{i}. {titulo}')\n",
        "\n",
        "# Recorrer cada fila e imprimir los datos al documento\n",
        "for _, fila in df_grupos_sorted.iterrows():\n",
        "    # Obtener los datos de cada fila\n",
        "    titulo = fila['Título']\n",
        "    Resumen = fila['Resumen']\n",
        "    URL = fila['URL del testigo']\n",
        "    notas = fila['Notas']\n",
        "\n",
        "    # Agregar el título y las notas al documento\n",
        "    #document.add_paragraph(f'{titulo}')\n",
        "    #document.add_paragraph(f'Notas: {notas}')\n",
        "    #document.add_paragraph(f'Link: {URL}')\n",
        "\n",
        "# Guardar el documento como un archivo de Word en la ruta especificada\n",
        "document.save('/content/drive/MyDrive/profepa-sintesis/Excel/SÍNTESISS.docx')\n",
        "print('Se ha creado el documento \"SÍNTESIsS.docx\" en la ruta especificada.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7TG08_S3ZGa",
        "outputId": "1a88f7d6-785a-42e9-9301-87d11551386b"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha creado el documento \"SÍNTESIsS.docx\" en la ruta especificada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######profepa análisis###########\n",
        "import os\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "\n",
        "# Ruta de la carpeta que contiene los archivos Excel\n",
        "ruta = '/content/drive/MyDrive/profepa-sintesis/Excel/PROFEPA'\n",
        "\n",
        "# Obtener la lista de archivos Excel en la carpeta\n",
        "archivos_excel = [archivo for archivo in os.listdir(ruta) if archivo.endswith('.xlsx')]\n",
        "\n",
        "# DataFrame final\n",
        "df_final = pd.DataFrame()\n",
        "\n",
        "# Recorrer los archivos Excel y cargarlos en el DataFrame final\n",
        "for i, archivo in enumerate(archivos_excel):\n",
        "    archivo_path = os.path.join(ruta, archivo)\n",
        "    df = pd.read_excel(archivo_path)\n",
        "\n",
        "    # Eliminar las filas correspondientes según el archivo\n",
        "    if i == 0:\n",
        "        df = df.iloc[1:]  # Eliminar la primera fila\n",
        "    else:\n",
        "        df = df.iloc[2:]  # Eliminar las tres primeras filas\n",
        "\n",
        "    # Agregar el DataFrame al DataFrame final\n",
        "    df_final = pd.concat([df_final, df], ignore_index=True)\n",
        "\n",
        "# Utilizar la primera fila como cabeceras\n",
        "df_final.columns = df_final.iloc[0]\n",
        "df_final = df_final.iloc[1:]\n",
        "\n",
        "# Convertimos las columnas 'Fecha' y 'Hora' a datetime\n",
        "df_final['Fecha'] = pd.to_datetime(df_final['Fecha'])\n",
        "df_final['Hora'] = pd.to_timedelta(df_final['Hora'])\n",
        "\n",
        "# Creamos una nueva columna con la fecha y hora juntas\n",
        "df_final['FechaHora'] = df_final['Fecha'] + df_final['Hora']\n",
        "\n",
        "# Definimos la fecha y hora de inicio y fin\n",
        "fecha_inicio = pd.to_datetime('2023-06-29 17:00:00')\n",
        "fecha_fin = pd.to_datetime('2023-06-30 06:00:00')\n",
        "\n",
        "# Filtramos el dataframe para que solo queden las filas dentro del rango de fecha y hora\n",
        "df_final = df_final[(df_final['FechaHora'] >= fecha_inicio) & (df_final['FechaHora'] <= fecha_fin)]\n",
        "\n",
        "#copiamos la columan titulo para trabajar sobre ella\n",
        "df_final['Título_analisis'] = df_final['Título']\n",
        "\n",
        "# Descargar los stopwords si no están descargados\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Obtener los stopwords en español\n",
        "stopwords_esp = set(stopwords.words('spanish'))\n",
        "\n",
        "# Función para eliminar palabras vacías y manejar valores nulos\n",
        "def eliminar_palabras_vacias(texto):\n",
        "    if isinstance(texto, str):  # Verificar si el valor no es nulo\n",
        "        texto = re.sub(r'[^\\w\\s]', '', texto)  # Eliminar caracteres no deseados utilizando re.sub()\n",
        "        texto = texto.strip()  # Eliminar espacios en blanco adicionales al inicio y al final\n",
        "        palabras = texto.split()\n",
        "        palabras_filtradas = [palabra for palabra in palabras if palabra not in stopwords_esp]\n",
        "        return ' '.join(palabras_filtradas).lower()\n",
        "    else:\n",
        "        return texto\n",
        "\n",
        "# Aplicar la función a la columna 'Título_analisis'\n",
        "df_final['Título_analisis'] = df_final['Título_analisis'].apply(eliminar_palabras_vacias)\n",
        "\n",
        "# Verificar y convertir a cadena los valores no nulos en la columna \"Título_analisis\"\n",
        "df_final['Título_analisis'] = df_final['Título_analisis'].apply(lambda x: str(x) if pd.notnull(x) else '')\n",
        "\n",
        "grupos = {}\n",
        "for i in range(len(df_final)):\n",
        "    titulo_i = df_final.iloc[i, df_final.columns.get_loc(\"Título_analisis\")]\n",
        "    if i not in grupos:\n",
        "        grupo_actual = len(grupos) + 1\n",
        "        grupos[i] = grupo_actual\n",
        "    else:\n",
        "        grupo_actual = grupos[i]\n",
        "    for j in range(i+1, len(df_final)):\n",
        "        titulo_j = df_final.iloc[j, df_final.columns.get_loc(\"Título_analisis\")]\n",
        "        titulo_j = str(titulo_j) if pd.notnull(titulo_j) else ''\n",
        "        palabras_iguales = set(titulo_i.lower().split()) & set(titulo_j.lower().split())\n",
        "        if len(palabras_iguales) >= 3:\n",
        "            if j not in grupos:\n",
        "                grupos[j] = grupo_actual\n",
        "            else:\n",
        "                grupo_j = grupos[j]\n",
        "                if grupo_j != grupo_actual:\n",
        "                    for k, v in grupos.items():\n",
        "                        if v == grupo_j:\n",
        "                            grupos[k] = grupo_actual\n",
        "\n",
        "# Agregar una columna al DataFrame para mostrar los grupos\n",
        "df_final['Grupo'] = [grupos[i] for i in range(len(df_final))]\n",
        "\n",
        "grupo_counts = df_final['Grupo'].value_counts()\n",
        "df_final['Notas'] = df_final['Grupo'].apply(lambda x: grupo_counts[x])\n",
        "\n",
        "# Eliminar filas con NaN en la columna \"Título\"\n",
        "df_final = df_final.dropna(subset=['Título'])\n",
        "\n",
        "# Crear una nueva columna \"resautom\" en el dataframe df_final.\n",
        "df_final[\"resautom\"] = \"\"\n",
        "\n",
        "# Recorrer cada celda de la columna \"Transcripción\".\n",
        "for index, row in df_final.iterrows():\n",
        "    document = row[\"Transcripción\"]\n",
        "\n",
        "    # Utilizar expresiones regulares para buscar las oraciones relevantes.\n",
        "    pattern = re.compile(r\"(.*?[.!?])\", re.IGNORECASE)\n",
        "    relevant_sentences = re.findall(pattern, document)\n",
        "    relevant_sentences = [sentence.strip() for sentence in relevant_sentences if \"Profepa\" in sentence.upper() or \"PROFEPA\" in sentence or \"Procuraduría Federal de Protección al Ambiente\" in sentence]\n",
        "\n",
        "    # Unir las oraciones relevantes en una sola cadena de texto.\n",
        "    summary_text = \". \".join(relevant_sentences)\n",
        "\n",
        "    # Agregar el resultado a la columna \"resautom\" en el dataframe.\n",
        "    df_final.at[index, \"resautom\"] = summary_text\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX9ErWpKDrT6",
        "outputId": "69344835-1a33-4b76-8b00-470f017f58e6"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################WORD indice profepa##################\n",
        "\n",
        "# Crear un documento de Word\n",
        "document = Document()\n",
        "\n",
        "# Establecer el tipo de letra y tamaño de fuente\n",
        "font_name = \"Montserrat\"\n",
        "font_size = Pt(12)\n",
        "document.styles['Normal'].font.name = font_name\n",
        "document.styles['Normal'].font.size = font_size\n",
        "\n",
        "# Establecer los márgenes del documento como \"Estrecho\"\n",
        "sections = document.sections\n",
        "for section in sections:\n",
        "    section.top_margin = section.bottom_margin = section.left_margin = section.right_margin = Pt(31.8)  # 0.44 pulgadas\n",
        "\n",
        "# Establecer el interlineado\n",
        "line_spacing = 1.5\n",
        "\n",
        "# Agregar un encabezado al documento\n",
        "document.add_heading('Índice', level=1)\n",
        "document.add_heading('PROFEPA', level=1)\n",
        "\n",
        "# Agrupar por \"Grupo\" y seleccionar la primera fila de cada grupo\n",
        "df_grupos = df_final.groupby('Grupo').first()\n",
        "\n",
        "# Ordenar el DataFrame por la columna \"Notas\" en orden descendente\n",
        "df_grupos_sorted = df_grupos.sort_values(by='Notas', ascending=False)\n",
        "\n",
        "# Crear una lista de todos los títulos\n",
        "titulos_list = df_grupos_sorted['Título'].tolist()\n",
        "\n",
        "# Agregar el listado de títulos como un índice al documento\n",
        "#document.add_heading('Índice', level=1)\n",
        "for i, titulo in enumerate(titulos_list, start=1):\n",
        "    document.add_paragraph(f'{i}. {titulo}')\n",
        "\n",
        "# Recorrer cada fila e imprimir los datos al documento\n",
        "for _, fila in df_grupos_sorted.iterrows():\n",
        "    # Obtener los datos de cada fila\n",
        "    titulo = fila['Título']\n",
        "    Resumen = fila['Resumen']\n",
        "    URL = fila['URL del testigo']\n",
        "    notas = fila['Notas']\n",
        "    resautom = fila['resautom']\n",
        "\n",
        "   # Agregar el título y las notas al documento\n",
        "    #document.add_heading(titulo, level=1)\n",
        "    #document.add_paragraph(f'Notas: {notas}')\n",
        "    #document.add_paragraph()\n",
        "    #document.add_paragraph(resautom)\n",
        "    #document.add_paragraph(f'Nota: {URL}')\n",
        "\n",
        "# Guardar el documento como un archivo de Word en la ruta especificada\n",
        "document.save('/content/drive/MyDrive/profepa-sintesis/Excel/SÍNTESISP.docx')\n",
        "print('Se ha creado el documento \"SÍNTESIsP.docx\" en la ruta especificada.')"
      ],
      "metadata": {
        "id": "dUCXwP16BJEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65a5fe1-1051-4f0d-bb91-b71c62593fcd"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha creado el documento \"SÍNTESIsP.docx\" en la ruta especificada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROFEPA Crear un documento de Word completo de notas sin indice############################\n",
        "document = Document()\n",
        "\n",
        "# Establecer el tipo de letra y tamaño de fuente\n",
        "font_name = \"Montserrat\"\n",
        "font_size = Pt(12)\n",
        "document.styles['Normal'].font.name = font_name\n",
        "document.styles['Normal'].font.size = font_size\n",
        "\n",
        "# Establecer los márgenes del documento como \"Estrecho\"\n",
        "sections = document.sections\n",
        "for section in sections:\n",
        "    section.top_margin = section.bottom_margin = section.left_margin = section.right_margin = Pt(31.8)  # 0.44 pulgadas\n",
        "\n",
        "# Establecer el interlineado\n",
        "line_spacing = 1.5\n",
        "\n",
        "# Agregar un encabezado al documento\n",
        "#document.add_heading('Índice', level=1)\n",
        "document.add_heading('PROFEPA', level=1)\n",
        "\n",
        "# Agrupar por \"Grupo\" y seleccionar la primera fila de cada grupo\n",
        "df_grupos = df_final.groupby('Grupo').first()\n",
        "\n",
        "# Ordenar el DataFrame por la columna \"Notas\" en orden descendente\n",
        "df_grupos_sorted = df_grupos.sort_values(by='Notas', ascending=False)\n",
        "\n",
        "# Crear una lista de todos los títulos\n",
        "titulos_list = df_grupos_sorted['Título'].tolist()\n",
        "\n",
        "# Recorrer cada fila e imprimir los datos al documento\n",
        "for _, fila in df_grupos_sorted.iterrows():\n",
        "    # Obtener los datos de cada fila\n",
        "    titulo = fila['Título']\n",
        "    Resumen = fila['Resumen']\n",
        "    URL = fila['URL del testigo']\n",
        "    notas = fila['Notas']\n",
        "    resautom = fila['resautom']\n",
        "\n",
        "   # Agregar el título y las notas al documento\n",
        "    document.add_heading(titulo, level=1)\n",
        "    #document.add_paragraph(f'Notas: {notas}')\n",
        "    document.add_paragraph()\n",
        "    document.add_paragraph(resautom)\n",
        "    document.add_paragraph(f'Nota: {URL}')\n",
        "\n",
        "# Guardar el documento como un archivo de Word en la ruta especificada\n",
        "document.save('/content/drive/MyDrive/profepa-sintesis/Excel/SÍNTESISPC.docx')\n",
        "print('Se ha creado el documento \"SÍNTESIsP.docx\" en la ruta especificada.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCa7GG0K98Zl",
        "outputId": "d5fc77ed-16ff-4fa4-9aa9-9f37fd685ebd"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha creado el documento \"SÍNTESIsP.docx\" en la ruta especificada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####3semarnat completo#####\n",
        "\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "\n",
        "# Crear un documento de Word SOLO NOTAS\n",
        "document = Document()\n",
        "\n",
        "# Establecer el tipo de letra y tamaño de fuente\n",
        "font_name = \"Montserrat\"\n",
        "font_size = Pt(12)\n",
        "document.styles['Normal'].font.name = font_name\n",
        "document.styles['Normal'].font.size = font_size\n",
        "\n",
        "# Establecer los márgenes del documento como \"Estrecho\"\n",
        "sections = document.sections\n",
        "for section in sections:\n",
        "    section.top_margin = section.bottom_margin = section.left_margin = section.right_margin = Pt(31.8)  # 0.44 pulgadas\n",
        "\n",
        "# Establecer el interlineado\n",
        "line_spacing = 1.5\n",
        "\n",
        "# Agregar un encabezado al documento\n",
        "document.add_heading('SEMARNAT', level=1)\n",
        "\n",
        "# Agrupar por \"Grupo\" y seleccionar la primera fila de cada grupo\n",
        "df_grupos = df_finalS.groupby('Grupo').first()\n",
        "\n",
        "# Ordenar el DataFrame por la columna \"Notas\" en orden descendente\n",
        "df_grupos_sorted = df_grupos.sort_values(by='Notas', ascending=False)\n",
        "\n",
        "# Crear una lista de todos los títulos\n",
        "titulos_list = df_grupos_sorted['Título'].tolist()\n",
        "\n",
        "# Recorrer cada fila e imprimir los datos al documento\n",
        "for _, fila in df_grupos_sorted.iterrows():\n",
        "    # Obtener los datos de cada fila\n",
        "    titulo = fila['Título']\n",
        "    Resumen = fila['Resumen']\n",
        "    URL = fila['URL del testigo']\n",
        "    notas = fila['Notas']\n",
        "    resautom = fila['resautom']\n",
        "\n",
        "    # Agregar el título y las notas al documento\n",
        "    document.add_heading(titulo, level=1)\n",
        "    document.add_paragraph()\n",
        "    document.add_paragraph(resautom)\n",
        "    document.add_paragraph(f'Nota: {URL}')\n",
        "\n",
        "# Guardar el documento como un archivo de Word en la ruta especificada\n",
        "document.save('/content/drive/MyDrive/profepa-sintesis/Excel/SÍNTESISSC.docx')\n",
        "print('Se ha creado el documento \"SÍNTESISPC.docx\" en la ruta especificada.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UwKhUbTARLR",
        "outputId": "6dd94fd0-40ec-4e80-ed3c-f9d942995a4f"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se ha creado el documento \"SÍNTESISPC.docx\" en la ruta especificada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########DOCUMENTO FINAL###################\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "\n",
        "# Ruta de la carpeta de imágenes JPG\n",
        "ruta_imagenes_jpg = \"/content/drive/MyDrive/Procuraduria/COMUNICACION SOCIAL/C.S. - PROFEPA/Diseño/Portadas-Síntesis/matjpg\"\n",
        "\n",
        "# Obtener la lista de imágenes JPG en la carpeta\n",
        "lista_imagenes_jpg = [imagen for imagen in os.listdir(ruta_imagenes_jpg) if imagen.lower().endswith(\".jpg\")]\n",
        "\n",
        "# Elegir una imagen al azar de la lista\n",
        "imagen_elegida_jpg = random.choice(lista_imagenes_jpg)\n",
        "\n",
        "# Ruta completa de la imagen JPG elegida\n",
        "ruta_imagen_elegida_jpg = os.path.join(ruta_imagenes_jpg, imagen_elegida_jpg)\n",
        "\n",
        "# Ruta de destino de la imagen PNG convertida\n",
        "ruta_imagen_convertida_png = \"/content/drive/MyDrive/profepa-sintesis/Excel/imagen.png\"\n",
        "\n",
        "# Abrir la imagen JPG con Pillow\n",
        "imagen_pil = Image.open(ruta_imagen_elegida_jpg)\n",
        "\n",
        "# Convertir la imagen a modo RGB\n",
        "imagen_rgb = imagen_pil.convert(\"RGB\")\n",
        "\n",
        "# Guardar la imagen en formato PNG en la ruta de destino\n",
        "imagen_rgb.save(ruta_imagen_convertida_png, \"PNG\")\n",
        "\n",
        "# Ruta de destino del documento de Word\n",
        "ruta_documento_final = \"/content/drive/MyDrive/profepa-sintesis/Excel/documento_word.docx\"\n",
        "\n",
        "# Crear un documento final de Word\n",
        "doc_final = Document()\n",
        "\n",
        "# Ajustar la imagen a un tamaño específico en pulgadas\n",
        "width = Inches(6.5)\n",
        "height = Inches(9)\n",
        "\n",
        "# Insertar la imagen en la primera página del documento final con el tamaño ajustado\n",
        "doc_final.add_picture(ruta_imagen_convertida_png, width=width, height=height)\n",
        "\n",
        "# Abrir y agregar la información del primer documento\n",
        "ruta_informacion1 = \"/content/drive/MyDrive/profepa-sintesis/Excel/SÍNTESISP.docx\"\n",
        "doc_informacion1 = Document(ruta_informacion1)\n",
        "for element in doc_informacion1.element.body:\n",
        "    doc_final.element.body.append(element)\n",
        "\n",
        "# Abrir y agregar la información del segundo documento\n",
        "ruta_informacion2 = \"/content/drive/MyDrive/profepa-sintesis/Excel/SÍNTESISS.docx\"\n",
        "doc_informacion2 = Document(ruta_informacion2)\n",
        "for element in doc_informacion2.element.body:\n",
        "    doc_final.element.body.append(element)\n",
        "\n",
        "# Abrir y agregar la información del tercer documento\n",
        "ruta_informacion3 = \"/content/drive/MyDrive/profepa-sintesis/Excel/SÍNTESISPC.docx\"\n",
        "doc_informacion3 = Document(ruta_informacion3)\n",
        "for element in doc_informacion3.element.body:\n",
        "    doc_final.element.body.append(element)\n",
        "\n",
        "# Abrir y agregar la información del cuarto documento\n",
        "ruta_informacion4 = \"/content/drive/MyDrive/profepa-sintesis/Excel/SÍNTESISSC.docx\"\n",
        "doc_informacion4 = Document(ruta_informacion4)\n",
        "for element in doc_informacion4.element.body:\n",
        "    doc_final.element.body.append(element)\n",
        "\n",
        "# Guardar el documento final con la imagen y la información\n",
        "doc_final.save(ruta_documento_final)\n",
        "\n",
        "print(\"SÍNTESIS TERMINADA\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtZUW3-Qgtck",
        "outputId": "cfcce1d6-5ad8-4424-be91-3e4a6526f206"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SÍNTESIS TERMINADA\n"
          ]
        }
      ]
    }
  ]
}